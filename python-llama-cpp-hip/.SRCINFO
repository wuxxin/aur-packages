pkgbase = python-llama-cpp-hip
	pkgdesc = Python bindings for llama.cpp (with HIP/ROCM support)
	pkgver = 0.3.16
	pkgrel = 1
	url = https://github.com/abetlen/llama-cpp-python
	arch = x86_64
	license = GPL-3.0-or-later
	checkdepends = python-pytest
	checkdepends = python-huggingface-hub
	checkdepends = python-scipy
	checkdepends = python-httpx
	checkdepends = python-fastapi
	checkdepends = python-sse-starlette
	checkdepends = python-pydantic-settings
	makedepends = python-scikit-build
	makedepends = python-installer
	makedepends = python-build
	makedepends = python-wheel
	makedepends = python-scikit-build-core
	makedepends = rocm-hip-sdk
	depends = python-typing_extensions
	depends = python-numpy
	depends = python-diskcache
	depends = hip-runtime-amd
	depends = hipblas
	depends = python-transformers
	depends = python-jinja
	depends = python-huggingface-hub
	depends = python-requests
	depends = python-openai
	optdepends = uvicorn
	optdepends = python-fastapi
	optdepends = python-pydantic-settings
	optdepends = python-sse-starlette
	optdepends = python-pyaml
	provides = python-llama-cpp
	conflicts = python-llama-cpp
	source = https://files.pythonhosted.org/packages/source/l/llama-cpp-python/llama_cpp_python-0.3.16.tar.gz
	sha256sums = 34ed0f9bd9431af045bb63d9324ae620ad0536653740e9bb163a2e1fcb973be6

pkgname = python-llama-cpp-hip
