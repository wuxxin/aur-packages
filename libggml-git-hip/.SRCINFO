pkgbase = libggml-git-hip
	pkgdesc = libggml, llama.cpp, whisper.cpp, python-llama-cpp - HIP accelerated, shared library, git version
	pkgver = 8121.r0.ga0c91e8
	pkgrel = 1
	url = https://github.com/ggml-org/llama.cpp
	arch = x86_64
	license = MIT
	license = Apache-2.0
	license = GPL-3.0-or-later
	makedepends = cmake
	makedepends = git
	makedepends = ninja
	makedepends = rocm-hip-sdk
	makedepends = rocm-toolchain
	makedepends = python-build
	makedepends = python-installer
	makedepends = python-wheel
	makedepends = python-setuptools
	makedepends = python-scikit-build-core
	makedepends = sdl2-compat
	makedepends = curl
	options = !lto
	options = !debug
	options = !buildflags
	source = llama.cpp::git+https://github.com/ggml-org/llama.cpp.git
	source = whisper.cpp::git+https://github.com/ggerganov/whisper.cpp.git
	source = llama-cpp-python::git+https://github.com/abetlen/llama-cpp-python.git
	source = README.md
	source = ggml.pc.in
	source = llama-patch-abi.py
	source = llama-shims.py
	source = llama-cpp-system.patch
	source = outetts-v1-integration-patch.sh
	source = outetts-create-speaker.py
	source = outetts-default-v3-female.json
	source = outetts-hf-dac-to-gguf.py
	source = outetts-hf-wavtokenizer-to-gguf.py
	sha256sums = SKIP
	sha256sums = SKIP
	sha256sums = SKIP
	sha256sums = 3c58baf589ece7e5deb9bca5e0b2ebf4f717a5ed518404a167b59523a4aaeb01
	sha256sums = 2470799a540d596c9639b2dd832cf2e327200f0277fe727480f1e7949d15dfb8
	sha256sums = e7430489ec842c7c10d6976e04c63023c24ebf9fa080ea3fad55ab19c636d875
	sha256sums = 3cff47657d41fecfe69314df2de602ef1be750dd68d84b21ac4986e5446b9391
	sha256sums = c5dc88f3ea1477da96b3b16e2402014d9f6928b60ccafa5e4ddc8baa2d972347
	sha256sums = 6db7755c0d22d7cf3392337bc09a79d812e905dd28ed66e87b92e98d86bfaaed
	sha256sums = 69e3fb8a3db3960098a5af1faaed62a0051ee837a17e275a532847f1a4e818d8
	sha256sums = 6bb6bacca60c9759741d849c2baf2af3f6263a51b759d67826ef39e1efc4436c
	sha256sums = bc863ead69651c137d8abf875fd2b61e872b5db0753ea0d67fdbe95583bbf6fd
	sha256sums = 54fe9143805ffe1cd4fd61548d85b9df99be413ef2fa7e83c4df8384520998e1

pkgname = libggml-git-hip
	pkgdesc = Tensor library for machine learning (HIP/ROCm optimized) - HEAD
	depends = hip-runtime-amd
	depends = hipblas
	depends = rocblas
	provides = libggml
	provides = libggml-git
	provides = libggml-git-hip
	conflicts = libggml
	conflicts = libggml-git
	conflicts = libggml-git-vulkan

pkgname = llama.cpp-git-ggml-hip
	pkgdesc = Port of Facebook's LLaMA model in C/C++ (git shared library build)
	depends = libggml-git-hip
	depends = curl
	depends = hip-runtime-amd
	depends = hipblas
	depends = rocblas
	optdepends = python-huggingface-hub: for DAC and WavTokenizer conversion
	optdepends = python-gguf: for DAC and WavTokenizer conversion
	optdepends = python-numpy: for speaker creation, DAC and WavTokenizer conversion
	optdepends = python-pytorch: for speaker creation, DAC and WavTokenizer conversion
	optdepends = python-torchaudio: for speaker creation
	optdepends = python-torchcodec: for speaker creation
	optdepends = python-transformers: for speaker creation
	provides = llama.cpp
	provides = llama.cpp-hip
	conflicts = llama.cpp
	conflicts = llama.cpp-hip

pkgname = whisper.cpp-git-ggml-hip
	pkgdesc = Port of OpenAI's Whisper model (git shared library build)
	depends = libggml-git-hip
	depends = sdl2-compat
	depends = hip-runtime-amd
	provides = whisper.cpp
	provides = whisper.cpp-hip

pkgname = python-llama-cpp-git-ggml-hip
	pkgdesc = Python bindings for llama.cpp (git shared library build)
	depends = llama.cpp-git-ggml-hip
	depends = libggml-git-hip
	depends = python-numpy
	provides = python-llama-cpp
	provides = python-llama-cpp-hip
